{
  "finished_at": "2026-01-20T04:55:45.247649Z",
  "meta": {
    "attempt": 1,
    "request_fingerprint": "de78f75812d3729f",
    "tag": "rest_pr_files_pr2284_page1"
  },
  "request": {
    "body": null,
    "headers": {
      "Accept": "application/vnd.github+json",
      "X-GitHub-Api-Version": "2022-11-28"
    },
    "method": "GET",
    "url": "https://api.github.com/repos/openai/openai-agents-python/pulls/2284/files?per_page=100&page=1"
  },
  "response": {
    "headers": {
      "access-control-allow-origin": "*",
      "access-control-expose-headers": "ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset",
      "cache-control": "private, max-age=60, s-maxage=60",
      "content-length": "25961",
      "content-security-policy": "default-src 'none'",
      "content-type": "application/json; charset=utf-8",
      "date": "Tue, 20 Jan 2026 04:55:45 GMT",
      "etag": "\"c6acf8efa0e9d12b8a64f71b54f31276011c15b8c8a2dba524f126de49529254\"",
      "github-authentication-token-expiration": "2026-02-19 04:41:20 UTC",
      "last-modified": "Sun, 11 Jan 2026 21:13:00 GMT",
      "referrer-policy": "origin-when-cross-origin, strict-origin-when-cross-origin",
      "server": "github.com",
      "strict-transport-security": "max-age=31536000; includeSubdomains; preload",
      "vary": "Accept, Authorization, Cookie, X-GitHub-OTP,Accept-Encoding, Accept, X-Requested-With",
      "x-accepted-oauth-scopes": "",
      "x-content-type-options": "nosniff",
      "x-frame-options": "deny",
      "x-github-api-version-selected": "2022-11-28",
      "x-github-media-type": "github.v3; format=json",
      "x-github-request-id": "DBB9:7699F:1662655:1F6CD86:696F0AD0",
      "x-oauth-scopes": "repo",
      "x-ratelimit-limit": "5000",
      "x-ratelimit-remaining": "4964",
      "x-ratelimit-reset": "1768885989",
      "x-ratelimit-resource": "core",
      "x-ratelimit-used": "36",
      "x-xss-protection": "0"
    },
    "json": [
      {
        "additions": 10,
        "blob_url": "https://github.com/openai/openai-agents-python/blob/4af265f2c57e5ac1e80a4de16fcc77e461039712/src%2Fagents%2Fextensions%2Fmemory%2F__init__.py",
        "changes": 10,
        "contents_url": "https://api.github.com/repos/openai/openai-agents-python/contents/src%2Fagents%2Fextensions%2Fmemory%2F__init__.py?ref=4af265f2c57e5ac1e80a4de16fcc77e461039712",
        "deletions": 0,
        "filename": "src/agents/extensions/memory/__init__.py",
        "patch": "@@ -12,6 +12,7 @@\n \r\n if TYPE_CHECKING:\r\n     from .advanced_sqlite_session import AdvancedSQLiteSession\r\n+    from .async_sqlite_session import AsyncSQLiteSession\r\n     from .dapr_session import (\r\n         DAPR_CONSISTENCY_EVENTUAL,\r\n         DAPR_CONSISTENCY_STRONG,\r\n@@ -23,6 +24,7 @@\n \r\n __all__: list[str] = [\r\n     \"AdvancedSQLiteSession\",\r\n+    \"AsyncSQLiteSession\",\r\n     \"DAPR_CONSISTENCY_EVENTUAL\",\r\n     \"DAPR_CONSISTENCY_STRONG\",\r\n     \"DaprSession\",\r\n@@ -74,6 +76,14 @@ def __getattr__(name: str) -> Any:\n         except ModuleNotFoundError as e:\r\n             raise ImportError(f\"Failed to import AdvancedSQLiteSession: {e}\") from e\r\n \r\n+    if name == \"AsyncSQLiteSession\":\r\n+        try:\r\n+            from .async_sqlite_session import AsyncSQLiteSession  # noqa: F401\r\n+\r\n+            return AsyncSQLiteSession\r\n+        except ModuleNotFoundError as e:\r\n+            raise ImportError(f\"Failed to import AsyncSQLiteSession: {e}\") from e\r\n+\r\n     if name == \"DaprSession\":\r\n         try:\r\n             from .dapr_session import DaprSession  # noqa: F401\r",
        "raw_url": "https://github.com/openai/openai-agents-python/raw/4af265f2c57e5ac1e80a4de16fcc77e461039712/src%2Fagents%2Fextensions%2Fmemory%2F__init__.py",
        "sha": "2c7d268a7648becd3723d58955bd249572f073ba",
        "status": "modified"
      },
      {
        "additions": 239,
        "blob_url": "https://github.com/openai/openai-agents-python/blob/4af265f2c57e5ac1e80a4de16fcc77e461039712/src%2Fagents%2Fextensions%2Fmemory%2Fasync_sqlite_session.py",
        "changes": 239,
        "contents_url": "https://api.github.com/repos/openai/openai-agents-python/contents/src%2Fagents%2Fextensions%2Fmemory%2Fasync_sqlite_session.py?ref=4af265f2c57e5ac1e80a4de16fcc77e461039712",
        "deletions": 0,
        "filename": "src/agents/extensions/memory/async_sqlite_session.py",
        "patch": "@@ -0,0 +1,239 @@\n+from __future__ import annotations\n+\n+import asyncio\n+import json\n+from collections.abc import AsyncIterator\n+from contextlib import asynccontextmanager\n+from pathlib import Path\n+from typing import cast\n+\n+import aiosqlite\n+\n+from ...items import TResponseInputItem\n+from ...memory import SessionABC\n+\n+\n+class AsyncSQLiteSession(SessionABC):\n+    \"\"\"Async SQLite-based implementation of session storage.\n+\n+    This implementation stores conversation history in a SQLite database.\n+    By default, uses an in-memory database that is lost when the process ends.\n+    For persistent storage, provide a file path.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        session_id: str,\n+        db_path: str | Path = \":memory:\",\n+        sessions_table: str = \"agent_sessions\",\n+        messages_table: str = \"agent_messages\",\n+    ):\n+        \"\"\"Initialize the async SQLite session.\n+\n+        Args:\n+            session_id: Unique identifier for the conversation session\n+            db_path: Path to the SQLite database file. Defaults to ':memory:' (in-memory database)\n+            sessions_table: Name of the table to store session metadata. Defaults to\n+                'agent_sessions'\n+            messages_table: Name of the table to store message data. Defaults to 'agent_messages'\n+        \"\"\"\n+        self.session_id = session_id\n+        self.db_path = db_path\n+        self.sessions_table = sessions_table\n+        self.messages_table = messages_table\n+        self._connection: aiosqlite.Connection | None = None\n+        self._lock = asyncio.Lock()\n+        self._init_lock = asyncio.Lock()\n+\n+    async def _init_db_for_connection(self, conn: aiosqlite.Connection) -> None:\n+        \"\"\"Initialize the database schema for a specific connection.\"\"\"\n+        await conn.execute(\n+            f\"\"\"\n+            CREATE TABLE IF NOT EXISTS {self.sessions_table} (\n+                session_id TEXT PRIMARY KEY,\n+                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n+                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n+            )\n+        \"\"\"\n+        )\n+\n+        await conn.execute(\n+            f\"\"\"\n+            CREATE TABLE IF NOT EXISTS {self.messages_table} (\n+                id INTEGER PRIMARY KEY AUTOINCREMENT,\n+                session_id TEXT NOT NULL,\n+                message_data TEXT NOT NULL,\n+                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n+                FOREIGN KEY (session_id) REFERENCES {self.sessions_table} (session_id)\n+                    ON DELETE CASCADE\n+            )\n+        \"\"\"\n+        )\n+\n+        await conn.execute(\n+            f\"\"\"\n+            CREATE INDEX IF NOT EXISTS idx_{self.messages_table}_session_id\n+            ON {self.messages_table} (session_id, id)\n+        \"\"\"\n+        )\n+\n+        await conn.commit()\n+\n+    async def _get_connection(self) -> aiosqlite.Connection:\n+        \"\"\"Get or create a database connection.\"\"\"\n+        if self._connection is not None:\n+            return self._connection\n+\n+        async with self._init_lock:\n+            if self._connection is None:\n+                self._connection = await aiosqlite.connect(str(self.db_path))\n+                await self._connection.execute(\"PRAGMA journal_mode=WAL\")\n+                await self._init_db_for_connection(self._connection)\n+\n+        return self._connection\n+\n+    @asynccontextmanager\n+    async def _locked_connection(self) -> AsyncIterator[aiosqlite.Connection]:\n+        \"\"\"Provide a connection under the session lock.\"\"\"\n+        async with self._lock:\n+            conn = await self._get_connection()\n+            yield conn\n+\n+    async def get_items(self, limit: int | None = None) -> list[TResponseInputItem]:\n+        \"\"\"Retrieve the conversation history for this session.\n+\n+        Args:\n+            limit: Maximum number of items to retrieve. If None, retrieves all items.\n+                   When specified, returns the latest N items in chronological order.\n+\n+        Returns:\n+            List of input items representing the conversation history\n+        \"\"\"\n+\n+        async with self._locked_connection() as conn:\n+            if limit is None:\n+                cursor = await conn.execute(\n+                    f\"\"\"\n+                    SELECT message_data FROM {self.messages_table}\n+                    WHERE session_id = ?\n+                    ORDER BY id ASC\n+                \"\"\",\n+                    (self.session_id,),\n+                )\n+            else:\n+                cursor = await conn.execute(\n+                    f\"\"\"\n+                    SELECT message_data FROM {self.messages_table}\n+                    WHERE session_id = ?\n+                    ORDER BY id DESC\n+                    LIMIT ?\n+                    \"\"\",\n+                    (self.session_id, limit),\n+                )\n+\n+            rows = list(await cursor.fetchall())\n+            await cursor.close()\n+\n+        if limit is not None:\n+            rows = rows[::-1]\n+\n+        items: list[TResponseInputItem] = []\n+        for (message_data,) in rows:\n+            try:\n+                item = json.loads(message_data)\n+                items.append(item)\n+            except json.JSONDecodeError:\n+                continue\n+\n+        return items\n+\n+    async def add_items(self, items: list[TResponseInputItem]) -> None:\n+        \"\"\"Add new items to the conversation history.\n+\n+        Args:\n+            items: List of input items to add to the history\n+        \"\"\"\n+        if not items:\n+            return\n+\n+        async with self._locked_connection() as conn:\n+            await conn.execute(\n+                f\"\"\"\n+                INSERT OR IGNORE INTO {self.sessions_table} (session_id) VALUES (?)\n+            \"\"\",\n+                (self.session_id,),\n+            )\n+\n+            message_data = [(self.session_id, json.dumps(item)) for item in items]\n+            await conn.executemany(\n+                f\"\"\"\n+                INSERT INTO {self.messages_table} (session_id, message_data) VALUES (?, ?)\n+            \"\"\",\n+                message_data,\n+            )\n+\n+            await conn.execute(\n+                f\"\"\"\n+                UPDATE {self.sessions_table}\n+                SET updated_at = CURRENT_TIMESTAMP\n+                WHERE session_id = ?\n+            \"\"\",\n+                (self.session_id,),\n+            )\n+\n+            await conn.commit()\n+\n+    async def pop_item(self) -> TResponseInputItem | None:\n+        \"\"\"Remove and return the most recent item from the session.\n+\n+        Returns:\n+            The most recent item if it exists, None if the session is empty\n+        \"\"\"\n+        async with self._locked_connection() as conn:\n+            cursor = await conn.execute(\n+                f\"\"\"\n+                DELETE FROM {self.messages_table}\n+                WHERE id = (\n+                    SELECT id FROM {self.messages_table}\n+                    WHERE session_id = ?\n+                    ORDER BY id DESC\n+                    LIMIT 1\n+                )\n+                RETURNING message_data\n+                \"\"\",\n+                (self.session_id,),\n+            )\n+\n+            result = await cursor.fetchone()\n+            await cursor.close()\n+            await conn.commit()\n+\n+        if result:\n+            message_data = result[0]\n+            try:\n+                return cast(TResponseInputItem, json.loads(message_data))\n+            except json.JSONDecodeError:\n+                return None\n+\n+        return None\n+\n+    async def clear_session(self) -> None:\n+        \"\"\"Clear all items for this session.\"\"\"\n+        async with self._locked_connection() as conn:\n+            await conn.execute(\n+                f\"DELETE FROM {self.messages_table} WHERE session_id = ?\",\n+                (self.session_id,),\n+            )\n+            await conn.execute(\n+                f\"DELETE FROM {self.sessions_table} WHERE session_id = ?\",\n+                (self.session_id,),\n+            )\n+            await conn.commit()\n+\n+    async def close(self) -> None:\n+        \"\"\"Close the database connection.\"\"\"\n+        if self._connection is None:\n+            return\n+        async with self._lock:\n+            await self._connection.close()\n+            self._connection = None",
        "raw_url": "https://github.com/openai/openai-agents-python/raw/4af265f2c57e5ac1e80a4de16fcc77e461039712/src%2Fagents%2Fextensions%2Fmemory%2Fasync_sqlite_session.py",
        "sha": "2f712f2e98accbf519571018b21189bd9d578f76",
        "status": "added"
      },
      {
        "additions": 4,
        "blob_url": "https://github.com/openai/openai-agents-python/blob/4af265f2c57e5ac1e80a4de16fcc77e461039712/src%2Fagents%2Fmemory%2Fsqlite_session.py",
        "changes": 8,
        "contents_url": "https://api.github.com/repos/openai/openai-agents-python/contents/src%2Fagents%2Fmemory%2Fsqlite_session.py?ref=4af265f2c57e5ac1e80a4de16fcc77e461039712",
        "deletions": 4,
        "filename": "src/agents/memory/sqlite_session.py",
        "patch": "@@ -101,7 +101,7 @@ def _init_db_for_connection(self, conn: sqlite3.Connection) -> None:\n         conn.execute(\n             f\"\"\"\n             CREATE INDEX IF NOT EXISTS idx_{self.messages_table}_session_id\n-            ON {self.messages_table} (session_id, created_at)\n+            ON {self.messages_table} (session_id, id)\n         \"\"\"\n         )\n \n@@ -127,7 +127,7 @@ def _get_items_sync():\n                         f\"\"\"\n                         SELECT message_data FROM {self.messages_table}\n                         WHERE session_id = ?\n-                        ORDER BY created_at ASC\n+                        ORDER BY id ASC\n                     \"\"\",\n                         (self.session_id,),\n                     )\n@@ -137,7 +137,7 @@ def _get_items_sync():\n                         f\"\"\"\n                         SELECT message_data FROM {self.messages_table}\n                         WHERE session_id = ?\n-                        ORDER BY created_at DESC\n+                        ORDER BY id DESC\n                         LIMIT ?\n                         \"\"\",\n                         (self.session_id, limit),\n@@ -223,7 +223,7 @@ def _pop_item_sync():\n                     WHERE id = (\n                         SELECT id FROM {self.messages_table}\n                         WHERE session_id = ?\n-                        ORDER BY created_at DESC\n+                        ORDER BY id DESC\n                         LIMIT 1\n                     )\n                     RETURNING message_data",
        "raw_url": "https://github.com/openai/openai-agents-python/raw/4af265f2c57e5ac1e80a4de16fcc77e461039712/src%2Fagents%2Fmemory%2Fsqlite_session.py",
        "sha": "bd935f9093240456c92a40199f9e8767c56e8998",
        "status": "modified"
      },
      {
        "additions": 300,
        "blob_url": "https://github.com/openai/openai-agents-python/blob/4af265f2c57e5ac1e80a4de16fcc77e461039712/tests%2Fextensions%2Fmemory%2Ftest_async_sqlite_session.py",
        "changes": 300,
        "contents_url": "https://api.github.com/repos/openai/openai-agents-python/contents/tests%2Fextensions%2Fmemory%2Ftest_async_sqlite_session.py?ref=4af265f2c57e5ac1e80a4de16fcc77e461039712",
        "deletions": 0,
        "filename": "tests/extensions/memory/test_async_sqlite_session.py",
        "patch": "@@ -0,0 +1,300 @@\n+\"\"\"Tests for AsyncSQLiteSession functionality.\"\"\"\n+\n+from __future__ import annotations\n+\n+import json\n+import tempfile\n+from collections.abc import Sequence\n+from datetime import datetime\n+from pathlib import Path\n+from typing import Any, cast\n+\n+import pytest\n+\n+pytest.importorskip(\"aiosqlite\")  # Skip tests if aiosqlite is not installed\n+\n+from agents import Agent, Runner, TResponseInputItem\n+from agents.extensions.memory import AsyncSQLiteSession\n+from tests.fake_model import FakeModel\n+from tests.test_responses import get_text_message\n+\n+pytestmark = pytest.mark.asyncio\n+\n+\n+@pytest.fixture\n+def agent() -> Agent:\n+    \"\"\"Fixture for a basic agent with a fake model.\"\"\"\n+    return Agent(name=\"test\", model=FakeModel())\n+\n+\n+def _item_ids(items: Sequence[TResponseInputItem]) -> list[str]:\n+    result: list[str] = []\n+    for item in items:\n+        item_dict = cast(dict[str, Any], item)\n+        result.append(cast(str, item_dict[\"id\"]))\n+    return result\n+\n+\n+async def test_async_sqlite_session_basic_flow():\n+    \"\"\"Test AsyncSQLiteSession add/get/clear behavior.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_basic.db\"\n+        session = AsyncSQLiteSession(\"async_basic\", db_path)\n+\n+        items: list[TResponseInputItem] = [\n+            {\"role\": \"user\", \"content\": \"Hello\"},\n+            {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n+        ]\n+\n+        await session.add_items(items)\n+        retrieved = await session.get_items()\n+        assert retrieved == items\n+\n+        await session.clear_session()\n+        assert await session.get_items() == []\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_pop_item():\n+    \"\"\"Test AsyncSQLiteSession pop_item behavior.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_pop.db\"\n+        session = AsyncSQLiteSession(\"async_pop\", db_path)\n+\n+        assert await session.pop_item() is None\n+\n+        items: list[TResponseInputItem] = [\n+            {\"role\": \"user\", \"content\": \"One\"},\n+            {\"role\": \"assistant\", \"content\": \"Two\"},\n+        ]\n+        await session.add_items(items)\n+\n+        popped = await session.pop_item()\n+        assert popped == items[-1]\n+        assert await session.get_items() == items[:-1]\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_get_items_limit():\n+    \"\"\"Test AsyncSQLiteSession get_items limit handling.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_limit.db\"\n+        session = AsyncSQLiteSession(\"async_limit\", db_path)\n+\n+        items: list[TResponseInputItem] = [\n+            {\"role\": \"user\", \"content\": \"Message 1\"},\n+            {\"role\": \"assistant\", \"content\": \"Response 1\"},\n+            {\"role\": \"user\", \"content\": \"Message 2\"},\n+        ]\n+        await session.add_items(items)\n+\n+        latest = await session.get_items(limit=2)\n+        assert latest == items[-2:]\n+\n+        none = await session.get_items(limit=0)\n+        assert none == []\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_unicode_content():\n+    \"\"\"Test AsyncSQLiteSession stores unicode content.\"\"\"\n+    session = AsyncSQLiteSession(\"async_unicode\")\n+    items: list[TResponseInputItem] = [\n+        {\"role\": \"user\", \"content\": \"こんにちは\"},\n+        {\"role\": \"assistant\", \"content\": \"Привет\"},\n+    ]\n+    await session.add_items(items)\n+\n+    retrieved = await session.get_items()\n+    assert retrieved == items\n+\n+    await session.close()\n+\n+\n+async def test_async_sqlite_session_runner_integration(agent: Agent):\n+    \"\"\"Test that AsyncSQLiteSession works correctly with the agent Runner.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_runner_integration.db\"\n+        session = AsyncSQLiteSession(\"runner_integration_test\", db_path)\n+\n+        assert isinstance(agent.model, FakeModel)\n+\n+        agent.model.set_next_output([get_text_message(\"San Francisco\")])\n+        result1 = await Runner.run(\n+            agent,\n+            \"What city is the Golden Gate Bridge in?\",\n+            session=session,\n+        )\n+        assert result1.final_output == \"San Francisco\"\n+\n+        agent.model.set_next_output([get_text_message(\"California\")])\n+        result2 = await Runner.run(agent, \"What state is it in?\", session=session)\n+        assert result2.final_output == \"California\"\n+\n+        last_input = agent.model.last_turn_args[\"input\"]\n+        assert isinstance(last_input, list)\n+        assert len(last_input) > 1\n+        assert any(\"Golden Gate Bridge\" in str(item.get(\"content\", \"\")) for item in last_input)\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_session_isolation(agent: Agent):\n+    \"\"\"Test that different session IDs result in isolated conversation histories.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_isolation.db\"\n+        session1 = AsyncSQLiteSession(\"session_1\", db_path)\n+        session2 = AsyncSQLiteSession(\"session_2\", db_path)\n+\n+        assert isinstance(agent.model, FakeModel)\n+        agent.model.set_next_output([get_text_message(\"I like cats.\")])\n+        await Runner.run(agent, \"I like cats.\", session=session1)\n+\n+        agent.model.set_next_output([get_text_message(\"I like dogs.\")])\n+        await Runner.run(agent, \"I like dogs.\", session=session2)\n+\n+        agent.model.set_next_output([get_text_message(\"You said you like cats.\")])\n+        result = await Runner.run(agent, \"What animal did I say I like?\", session=session1)\n+        assert \"cats\" in result.final_output.lower()\n+        assert \"dogs\" not in result.final_output.lower()\n+\n+        await session1.close()\n+        await session2.close()\n+\n+\n+async def test_async_sqlite_session_add_empty_items_list():\n+    \"\"\"Test that adding an empty list of items is a no-op.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_add_empty.db\"\n+        session = AsyncSQLiteSession(\"add_empty_test\", db_path)\n+\n+        assert await session.get_items() == []\n+        await session.add_items([])\n+        assert await session.get_items() == []\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_pop_from_empty_session():\n+    \"\"\"Test that pop_item returns None on an empty session.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_pop_empty.db\"\n+        session = AsyncSQLiteSession(\"empty_session\", db_path)\n+\n+        popped = await session.pop_item()\n+        assert popped is None\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_get_items_with_limit_more_than_available():\n+    \"\"\"Test limit behavior when requesting more items than exist.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_limit_more.db\"\n+        session = AsyncSQLiteSession(\"limit_more_test\", db_path)\n+\n+        items: list[TResponseInputItem] = [\n+            {\"role\": \"user\", \"content\": \"1\"},\n+            {\"role\": \"assistant\", \"content\": \"2\"},\n+            {\"role\": \"user\", \"content\": \"3\"},\n+            {\"role\": \"assistant\", \"content\": \"4\"},\n+        ]\n+        await session.add_items(items)\n+\n+        retrieved = await session.get_items(limit=10)\n+        assert retrieved == items\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_get_items_same_timestamp_consistent_order():\n+    \"\"\"Test that items with identical timestamps keep insertion order.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_same_timestamp.db\"\n+        session = AsyncSQLiteSession(\"same_timestamp_test\", db_path)\n+\n+        older_item = cast(\n+            TResponseInputItem, {\"id\": \"older_same_ts\", \"role\": \"user\", \"content\": \"old\"}\n+        )\n+        reasoning_item = cast(TResponseInputItem, {\"id\": \"rs_same_ts\", \"type\": \"reasoning\"})\n+        message_item = cast(\n+            TResponseInputItem,\n+            {\"id\": \"msg_same_ts\", \"type\": \"message\", \"role\": \"assistant\", \"content\": []},\n+        )\n+\n+        await session.add_items([older_item])\n+        await session.add_items([reasoning_item, message_item])\n+\n+        conn = await session._get_connection()\n+        cursor = await conn.execute(\n+            f\"SELECT id, message_data FROM {session.messages_table} WHERE session_id = ?\",\n+            (session.session_id,),\n+        )\n+        rows = await cursor.fetchall()\n+        await cursor.close()\n+\n+        id_map: dict[str, int] = {\n+            cast(str, json.loads(message_json)[\"id\"]): cast(int, row_id)\n+            for row_id, message_json in rows\n+        }\n+\n+        shared = datetime(2025, 10, 15, 17, 26, 39, 132483)\n+        shared_str = shared.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n+        await conn.execute(\n+            f\"\"\"\n+            UPDATE {session.messages_table}\n+            SET created_at = ?\n+            WHERE id IN (?, ?, ?)\n+            \"\"\",\n+            (\n+                shared_str,\n+                id_map[\"older_same_ts\"],\n+                id_map[\"rs_same_ts\"],\n+                id_map[\"msg_same_ts\"],\n+            ),\n+        )\n+        await conn.commit()\n+\n+        retrieved = await session.get_items()\n+        assert _item_ids(retrieved) == [\"older_same_ts\", \"rs_same_ts\", \"msg_same_ts\"]\n+\n+        latest_two = await session.get_items(limit=2)\n+        assert _item_ids(latest_two) == [\"rs_same_ts\", \"msg_same_ts\"]\n+\n+        await session.close()\n+\n+\n+async def test_async_sqlite_session_pop_item_same_timestamp_returns_latest():\n+    \"\"\"Test that pop_item returns the newest item when timestamps tie.\"\"\"\n+    with tempfile.TemporaryDirectory() as temp_dir:\n+        db_path = Path(temp_dir) / \"async_same_timestamp_pop.db\"\n+        session = AsyncSQLiteSession(\"same_timestamp_pop_test\", db_path)\n+\n+        reasoning_item = cast(TResponseInputItem, {\"id\": \"rs_pop_same_ts\", \"type\": \"reasoning\"})\n+        message_item = cast(\n+            TResponseInputItem,\n+            {\"id\": \"msg_pop_same_ts\", \"type\": \"message\", \"role\": \"assistant\", \"content\": []},\n+        )\n+\n+        await session.add_items([reasoning_item, message_item])\n+\n+        conn = await session._get_connection()\n+        shared = datetime(2025, 10, 15, 17, 26, 39, 132483)\n+        shared_str = shared.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n+        await conn.execute(\n+            f\"UPDATE {session.messages_table} SET created_at = ? WHERE session_id = ?\",\n+            (shared_str, session.session_id),\n+        )\n+        await conn.commit()\n+\n+        popped = await session.pop_item()\n+        assert popped is not None\n+        assert cast(dict[str, Any], popped)[\"id\"] == \"msg_pop_same_ts\"\n+\n+        remaining = await session.get_items()\n+        assert _item_ids(remaining) == [\"rs_pop_same_ts\"]\n+\n+        await session.close()",
        "raw_url": "https://github.com/openai/openai-agents-python/raw/4af265f2c57e5ac1e80a4de16fcc77e461039712/tests%2Fextensions%2Fmemory%2Ftest_async_sqlite_session.py",
        "sha": "71a13b3b92b61a3a9f7bfc9ed516762eaa81cbf0",
        "status": "added"
      }
    ],
    "status": 200
  },
  "started_at": "2026-01-20T04:55:44.642735Z"
}
