{
  "finished_at": "2026-01-20T04:58:34.859055Z",
  "meta": {
    "attempt": 1,
    "request_fingerprint": "b8fdedcbdab679be",
    "tag": "rest_pr_files_pr2338_page1"
  },
  "request": {
    "body": null,
    "headers": {
      "Accept": "application/vnd.github+json",
      "X-GitHub-Api-Version": "2022-11-28"
    },
    "method": "GET",
    "url": "https://api.github.com/repos/openai/openai-agents-python/pulls/2338/files?per_page=100&page=1"
  },
  "response": {
    "headers": {
      "access-control-allow-origin": "*",
      "access-control-expose-headers": "ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset",
      "cache-control": "private, max-age=60, s-maxage=60",
      "content-length": "30627",
      "content-security-policy": "default-src 'none'",
      "content-type": "application/json; charset=utf-8",
      "date": "Tue, 20 Jan 2026 04:58:34 GMT",
      "etag": "\"8b5b761e58c9e41fe5f08d4fb3e771fb575ef0644649577f1c757190e28e4e8f\"",
      "github-authentication-token-expiration": "2026-02-19 04:41:20 UTC",
      "last-modified": "Tue, 20 Jan 2026 02:23:13 GMT",
      "referrer-policy": "origin-when-cross-origin, strict-origin-when-cross-origin",
      "server": "github.com",
      "strict-transport-security": "max-age=31536000; includeSubdomains; preload",
      "vary": "Accept, Authorization, Cookie, X-GitHub-OTP,Accept-Encoding, Accept, X-Requested-With",
      "x-accepted-oauth-scopes": "",
      "x-content-type-options": "nosniff",
      "x-frame-options": "deny",
      "x-github-api-version-selected": "2022-11-28",
      "x-github-media-type": "github.v3; format=json",
      "x-github-request-id": "DD4F:EFCF3:1622644:1F2E511:696F0B7A",
      "x-oauth-scopes": "repo",
      "x-ratelimit-limit": "5000",
      "x-ratelimit-remaining": "4924",
      "x-ratelimit-reset": "1768885989",
      "x-ratelimit-resource": "core",
      "x-ratelimit-used": "76",
      "x-xss-protection": "0"
    },
    "json": [
      {
        "additions": 29,
        "blob_url": "https://github.com/openai/openai-agents-python/blob/4d180fa0d132b29bc2a5a8f36302f08b576d1e77/docs%2Fja%2Fcontext.md",
        "changes": 58,
        "contents_url": "https://api.github.com/repos/openai/openai-agents-python/contents/docs%2Fja%2Fcontext.md?ref=4d180fa0d132b29bc2a5a8f36302f08b576d1e77",
        "deletions": 29,
        "filename": "docs/ja/context.md",
        "patch": "@@ -4,30 +4,30 @@ search:\n ---\n # コンテキスト管理\n \n-コンテキストは多義的な用語です。重要になるコンテキストには主に 2 つのクラスがあります。\n+コンテキストは多義的な用語です。気にするべきコンテキストには主に 2 つの種類があります。\n \n-1. コード内でローカルに利用可能なコンテキスト: これは、ツール関数の実行時、`on_handoff` のようなコールバック中、ライフサイクルフック中などに必要となるデータや依存関係です。\n-2. LLM に提供されるコンテキスト: これは、応答を生成する際に LLM が参照できるデータです。\n+1. コード側でローカルに利用できるコンテキスト: ツール関数の実行時、`on_handoff` のようなコールバック、ライフサイクルフックなどで必要になり得るデータや依存関係です。\n+2. LLM が利用できるコンテキスト: LLM が応答を生成する際に目にするデータです。\n \n ## ローカルコンテキスト\n \n-これは、[`RunContextWrapper`][agents.run_context.RunContextWrapper] クラスおよびその中の [`context`][agents.run_context.RunContextWrapper.context] プロパティで表されます。動作の流れは次のとおりです。\n+これは [`RunContextWrapper`][agents.run_context.RunContextWrapper] クラスと、その中の [`context`][agents.run_context.RunContextWrapper.context] プロパティで表現されます。仕組みは次のとおりです。\n \n-1. 任意の Python オブジェクトを作成します。一般的には dataclass や Pydantic オブジェクトを使うパターンが多いです。\n-2. そのオブジェクトを各種実行メソッドに渡します（例: `Runner.run(..., **context=whatever**)`）。\n-3. すべてのツール呼び出しやライフサイクルフックなどには、`RunContextWrapper[T]` というラッパーオブジェクトが渡されます。ここで `T` はコンテキストオブジェクトの型を表し、`wrapper.context` からアクセスできます。\n+1. 任意の Python オブジェクトを作成します。一般的なパターンは、dataclass または Pydantic オブジェクトを使うことです。\n+2. そのオブジェクトを各種 run メソッドに渡します（例: `Runner.run(..., context=whatever)`）。\n+3. すべてのツール呼び出しやライフサイクルフックなどには、ラッパーオブジェクト `RunContextWrapper[T]` が渡されます。ここで `T` はコンテキストオブジェクトの型を表し、`wrapper.context` でアクセスできます。\n \n- **最も重要** な注意点: 特定のエージェント実行に関わるすべてのエージェント、ツール関数、ライフサイクルなどは、同じコンテキストの _型_ を使用しなければなりません。\n+**最も重要**な注意点は、あるエージェント実行におけるすべてのエージェント、ツール関数、ライフサイクルなどが、同じコンテキストの _型_ を使わなければならないことです。\n \n コンテキストは次のような用途に使えます。\n \n--   実行時のコンテキストデータ（例: ユーザー名 / uid など、ユーザーに関する情報）\n--   依存関係（例: logger オブジェクト、データ取得処理など）\n+-   実行に関するコンテキストデータ（例: ユーザー名 / uid や、ユーザーに関するその他の情報など）\n+-   依存関係（例: logger オブジェクト、データフェッチャーなど）\n -   ヘルパー関数\n \n-!!! danger \"注意\"\n+!!! danger \"Note\"\n \n-    コンテキストオブジェクトは LLM には **送信されません**。読み取り・書き込み・メソッド呼び出しが可能な、純粋にローカルなオブジェクトです。\n+    コンテキストオブジェクトは LLM に送信され **ません**。これは純粋にローカルなオブジェクトであり、読み取り、書き込み、メソッド呼び出しができます。\n \n ```python\n import asyncio\n@@ -67,17 +67,17 @@ if __name__ == \"__main__\":\n ```\n \n 1. これはコンテキストオブジェクトです。ここでは dataclass を使っていますが、任意の型を使えます。\n-2. これはツールです。`RunContextWrapper[UserInfo]` を受け取るのがわかります。ツール実装はコンテキストから読み取ります。\n-3. 型チェッカーがエラーを検出できるように、エージェントにはジェネリックの `UserInfo` を付与します（たとえば、異なるコンテキスト型を受け取るツールを渡そうとした場合など）。\n-4. `run` 関数にコンテキストを渡します。\n-5. エージェントはツールを正しく呼び出し、年齢を取得します。\n+2. これはツールです。`RunContextWrapper[UserInfo]` を受け取っていることが分かります。ツール実装はコンテキストから読み取ります。\n+3. 型チェッカーがエラーを検出できるように、エージェントをジェネリック `UserInfo` としてマークします（例: 異なるコンテキスト型を受け取るツールを渡そうとした場合）。\n+4. コンテキストは `run` 関数に渡されます。\n+5. エージェントは正しくツールを呼び出し、年齢を取得します。\n \n ---\n \n-### 応用: `ToolContext`\n+### 上級: `ToolContext`\n \n-一部のケースでは、実行中のツールに関する追加メタデータ（名前、呼び出し ID、raw 引数文字列など）にアクセスしたいことがあります。  \n-その場合は、`RunContextWrapper` を拡張した [`ToolContext`][agents.tool_context.ToolContext] クラスを使用できます。\n+場合によっては、実行中のツールに関する追加メタデータ（名前、call ID、raw 引数文字列など）にアクセスしたいことがあります。  \n+その場合は、`RunContextWrapper` を拡張する [`ToolContext`][agents.tool_context.ToolContext] クラスを使えます。\n \n ```python\n from typing import Annotated\n@@ -105,23 +105,23 @@ agent = Agent(\n )\n ```\n \n-`ToolContext` は `RunContextWrapper` と同じ `.context` プロパティに加え、  \n+`ToolContext` は `RunContextWrapper` と同じ `.context` プロパティに加えて、  \n 現在のツール呼び出しに固有の追加フィールドを提供します。\n \n-- `tool_name` – 呼び出されているツールの名前  \n-- `tool_call_id` – このツール呼び出しの一意の識別子  \n+- `tool_name` – 呼び出されるツールの名前  \n+- `tool_call_id` – このツール呼び出しの一意識別子  \n - `tool_arguments` – ツールに渡された raw 引数文字列  \n \n-実行時にツールレベルのメタデータが必要な場合は `ToolContext` を使用してください。  \n-エージェントとツール間で一般的なコンテキストを共有するには、`RunContextWrapper` で十分です。\n+実行中にツールレベルのメタデータが必要な場合は `ToolContext` を使用してください。  \n+エージェントとツール間での一般的なコンテキスト共有には、`RunContextWrapper` で十分です。\n \n ---\n \n ## エージェント / LLM コンテキスト\n \n-LLM が呼び出されるとき、参照できるのは会話履歴に含まれるデータ **のみ** です。つまり、LLM に新しいデータを利用させたい場合は、そのデータが履歴で参照可能になるように提供する必要があります。方法はいくつかあります。\n+LLM が呼び出されるとき、LLM が見られるデータは会話履歴のもの **だけ** です。つまり、新しいデータを LLM から利用できるようにしたい場合は、それが履歴内で利用可能になる方法で行う必要があります。方法はいくつかあります。\n \n-1. エージェントの `instructions` に追加します。これは「システムプロンプト」または「開発者メッセージ」とも呼ばれます。システムプロンプトは静的な文字列でも、コンテキストを受け取って文字列を出力する動的な関数でも構いません。常に有用な情報（例: ユーザー名や現在の日付）に適した一般的な手法です。\n-2. `Runner.run` を呼び出す際の `input` に追加します。これは `instructions` の手法に似ていますが、[指揮系統](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command) の下位にメッセージを配置できます。\n-3. 関数ツール経由で公開します。これはオンデマンドのコンテキストに有用で、必要なときに LLM がそのデータを取得するためにツールを呼び出せます。\n-4. 検索による取得や Web 検索を使用します。これらは、ファイルやデータベースから関連データを取得できる（retrieval）ツール、または Web から取得できる（Web 検索）ツールです。関連するコンテキストデータに基づいて応答を「グラウンディング」するのに役立ちます。\n\\ No newline at end of file\n+1. Agent の `instructions` に追加します。これは「system prompt」や「developer message」とも呼ばれます。システムプロンプトは静的な文字列にすることも、コンテキストを受け取って文字列を出力する動的な関数にすることもできます。これは、常に有用な情報（例: ユーザーの名前や現在日付など）に対してよく使われる戦術です。\n+2. `Runner.run` 関数を呼び出す際に `input` に追加します。これは `instructions` の戦術に似ていますが、[chain of command](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command) の中でより下位のメッセージを持てます。\n+3. 関数ツールとして公開します。これは _オンデマンド_ なコンテキストに有用です。つまり、LLM がいつデータが必要かを判断し、そのデータを取得するためにツールを呼び出せます。\n+4. 検索や Web 検索を使います。これらは、ファイルやデータベース（検索）や Web（Web 検索）から関連データを取得できる特殊なツールです。これは、関連するコンテキストデータに基づいて応答を「グラウンディング」するのに有用です。\n\\ No newline at end of file",
        "raw_url": "https://github.com/openai/openai-agents-python/raw/4d180fa0d132b29bc2a5a8f36302f08b576d1e77/docs%2Fja%2Fcontext.md",
        "sha": "c9cd89af1488e0eff5d140caa9e08e38325934c8",
        "status": "modified"
      },
      {
        "additions": 31,
        "blob_url": "https://github.com/openai/openai-agents-python/blob/4d180fa0d132b29bc2a5a8f36302f08b576d1e77/docs%2Fko%2Fcontext.md",
        "changes": 62,
        "contents_url": "https://api.github.com/repos/openai/openai-agents-python/contents/docs%2Fko%2Fcontext.md?ref=4d180fa0d132b29bc2a5a8f36302f08b576d1e77",
        "deletions": 31,
        "filename": "docs/ko/context.md",
        "patch": "@@ -4,30 +4,30 @@ search:\n ---\n # 컨텍스트 관리\n \n-컨텍스트라는 용어는 여러 의미로 사용됩니다. 여기서 중요한 컨텍스트는 두 가지입니다:\n+컨텍스트는 의미가 중첩된 용어입니다. 관심을 가질 수 있는 컨텍스트는 크게 두 가지 범주가 있습니다:\n \n-1. 코드에서 로컬로 사용할 수 있는 컨텍스트: 도구 함수 실행 시, `on_handoff` 같은 콜백, 라이프사이클 훅 등에서 필요할 수 있는 데이터와 의존성\n-2. LLM 에서 사용할 수 있는 컨텍스트: LLM 이 응답을 생성할 때 볼 수 있는 데이터\n+1. 코드에서 로컬로 사용할 수 있는 컨텍스트: 도구 함수 실행 시, `on_handoff` 같은 콜백 중, 라이프사이클 훅 등에서 필요할 수 있는 데이터와 의존성입니다\n+2. LLM에서 사용할 수 있는 컨텍스트: 응답을 생성할 때 LLM이 보게 되는 데이터입니다\n \n ## 로컬 컨텍스트\n \n-이는 [`RunContextWrapper`][agents.run_context.RunContextWrapper] 클래스와 그 안의 [`context`][agents.run_context.RunContextWrapper.context] 속성으로 표현됩니다. 동작 방식은 다음과 같습니다:\n+이는 [`RunContextWrapper`][agents.run_context.RunContextWrapper] 클래스와 그 안의 [`context`][agents.run_context.RunContextWrapper.context] 프로퍼티로 표현됩니다. 동작 방식은 다음과 같습니다:\n \n-1. 원하는 Python 객체를 만듭니다. 일반적으로 dataclass 또는 Pydantic 객체를 사용합니다\n-2. 해당 객체를 다양한 실행 메서드에 전달합니다(예: `Runner.run(..., **context=whatever**))`\n-3. 모든 도구 호출, 라이프사이클 훅 등에는 `RunContextWrapper[T]` 래퍼 객체가 전달되며, 여기서 `T` 는 컨텍스트 객체 타입을 나타내며 `wrapper.context` 를 통해 접근할 수 있습니다\n+1. 원하는 어떤 파이썬 객체든 생성합니다. 흔한 패턴은 dataclass 또는 Pydantic 객체를 사용하는 것입니다\n+2. 해당 객체를 다양한 run 메서드(예: `Runner.run(..., context=whatever)`)에 전달합니다\n+3. 모든 도구 호출, 라이프사이클 훅 등에는 래퍼 객체 `RunContextWrapper[T]`가 전달되며, 여기서 `T`는 `wrapper.context`로 접근할 수 있는 컨텍스트 객체의 타입을 나타냅니다\n \n-가장 **중요한** 점: 특정 agent run 에 대해 각 에이전트, 도구 함수, 라이프사이클 등은 동일한 _type_ 의 컨텍스트를 사용해야 합니다.\n+가장 **중요한** 점: 특정 에이전트 run에 대해, 해당 run에서 사용되는 모든 에이전트, 도구 함수, 라이프사이클 등은 동일한 컨텍스트 _타입_을 사용해야 합니다\n \n 컨텍스트는 다음과 같은 용도로 사용할 수 있습니다:\n \n--   실행을 위한 컨텍스트 데이터(예: 사용자 이름/uid 또는 사용자에 대한 기타 정보)\n--   의존성(예: 로거 객체, 데이터 페처 등)\n--   헬퍼 함수\n+- 실행에 대한 컨텍스트 데이터(예: 사용자 이름/uid 또는 사용자에 대한 기타 정보)\n+- 의존성(예: 로거 객체, 데이터 페처 등)\n+- 헬퍼 함수\n \n-!!! danger \"주의\"\n+!!! danger \"Note\"\n \n-    컨텍스트 객체는 LLM 에게 **전송되지 않습니다**. 순수하게 로컬 객체이며, 읽기/쓰기 및 메서드 호출이 가능합니다.\n+    컨텍스트 객체는 **LLM에 전송되지 않습니다**. 이는 순수하게 로컬 객체로, 읽고/쓰고/메서드를 호출할 수 있습니다\n \n ```python\n import asyncio\n@@ -66,18 +66,18 @@ if __name__ == \"__main__\":\n     asyncio.run(main())\n ```\n \n-1. 이것이 컨텍스트 객체입니다. 여기서는 dataclass 를 사용했지만, 어떤 타입이든 사용할 수 있습니다.\n-2. 이것은 도구입니다. `RunContextWrapper[UserInfo]` 를 받는 것을 볼 수 있습니다. 도구 구현은 컨텍스트에서 값을 읽습니다.\n-3. 에이전트에 제네릭 `UserInfo` 를 지정하여, 타입 체커가 오류를 잡을 수 있게 합니다(예: 다른 컨텍스트 타입을 받는 도구를 전달하려 할 때).\n-4. 컨텍스트는 `run` 함수로 전달됩니다.\n-5. 에이전트는 도구를 올바르게 호출하여 나이를 가져옵니다.\n+1. 이것이 컨텍스트 객체입니다. 여기서는 dataclass를 사용했지만 어떤 타입이든 사용할 수 있습니다\n+2. 이것은 도구입니다. `RunContextWrapper[UserInfo]`를 받는 것을 볼 수 있습니다. 도구 구현은 컨텍스트에서 값을 읽습니다\n+3. 타입체커가 오류를 잡을 수 있도록(예: 다른 컨텍스트 타입을 받는 도구를 전달하려고 할 때) 에이전트에 제네릭 `UserInfo`를 표시합니다\n+4. 컨텍스트는 `run` 함수에 전달됩니다\n+5. 에이전트는 도구를 올바르게 호출하고 나이를 얻습니다\n \n ---\n \n ### 고급: `ToolContext`\n \n-경우에 따라 실행 중인 도구의 추가 메타데이터(예: 이름, 호출 ID, 원문 인자 문자열)에 접근하고 싶을 수 있습니다.  \n-이를 위해 `RunContextWrapper` 를 확장한 [`ToolContext`][agents.tool_context.ToolContext] 클래스를 사용할 수 있습니다.\n+일부 경우에는 실행 중인 도구에 대한 추가 메타데이터(예: 이름, 호출 ID, 원문 인자 문자열)에 접근하고 싶을 수 있습니다.  \n+이를 위해 `RunContextWrapper`를 확장한 [`ToolContext`][agents.tool_context.ToolContext] 클래스를 사용할 수 있습니다.\n \n ```python\n from typing import Annotated\n@@ -105,23 +105,23 @@ agent = Agent(\n )\n ```\n \n-`ToolContext` 는 `RunContextWrapper` 와 동일한 `.context` 속성을 제공하며,  \n-현재 도구 호출에 특화된 추가 필드가 있습니다:\n+`ToolContext`는 `RunContextWrapper`와 동일한 `.context` 프로퍼티를 제공하며,  \n+여기에 더해 현재 도구 호출에 특화된 추가 필드를 제공합니다:\n \n-- `tool_name` – 호출 중인 도구의 이름  \n-- `tool_call_id` – 이 도구 호출의 고유 식별자  \n+- `tool_name` – 호출되는 도구의 이름  \n+- `tool_call_id` – 이 도구 호출을 위한 고유 식별자  \n - `tool_arguments` – 도구에 전달된 원문 인자 문자열  \n \n-실행 중 도구 수준의 메타데이터가 필요할 때 `ToolContext` 를 사용하세요.  \n-에이전트와 도구 간의 일반적인 컨텍스트 공유에는 `RunContextWrapper` 로 충분합니다.\n+실행 중 도구 수준의 메타데이터가 필요할 때 `ToolContext`를 사용하세요.  \n+에이전트와 도구 간 일반적인 컨텍스트 공유에는 `RunContextWrapper`만으로도 충분합니다.\n \n ---\n \n ## 에이전트/LLM 컨텍스트\n \n-LLM 이 호출될 때, LLM 이 볼 수 있는 **유일한** 데이터는 대화 히스토리에서 옵니다. 즉, 새로운 데이터를 LLM 이 보게 하려면 그 히스토리에 포함되도록 해야 합니다. 방법은 몇 가지가 있습니다:\n+LLM이 호출될 때, LLM이 볼 수 있는 데이터는 대화 히스토리에서 온 것 **뿐**입니다. 즉, 새로운 데이터를 LLM에서 사용할 수 있게 만들고 싶다면, 해당 데이터가 그 히스토리에 포함되도록 하는 방식으로 해야 합니다. 이를 위한 몇 가지 방법이 있습니다:\n \n-1. 에이전트 `instructions` 에 추가하세요. 이는 \"system prompt\" 또는 \"developer message\" 라고도 합니다. 시스템 프롬프트는 정적 문자열일 수도 있고, 컨텍스트를 입력받아 문자열을 출력하는 동적 함수일 수도 있습니다. 항상 유용한 정보(예: 사용자 이름이나 현재 날짜)에 흔히 사용됩니다\n-2. `Runner.run` 함수를 호출할 때 `input` 에 추가하세요. 이는 `instructions` 전략과 유사하지만, [지휘 계통](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command) 하위의 메시지를 사용할 수 있습니다\n-3. 함수 도구로 노출하세요. 이는 _on-demand_ 컨텍스트에 유용합니다 — LLM 이 데이터가 필요할 때를 스스로 판단하고, 도구를 호출해 해당 데이터를 가져옵니다\n-4. 파일 검색 또는 웹 검색을 사용하세요. 이는 파일이나 데이터베이스에서 관련 데이터를 가져오거나(파일 검색), 웹에서 가져오는(웹 검색) 특수 도구입니다. 관련 컨텍스트 데이터로 응답을 \"그라운딩\" 하는 데 유용합니다\n\\ No newline at end of file\n+1. Agent `instructions`에 추가할 수 있습니다. 이는 \"system prompt\" 또는 \"developer message\"라고도 합니다. 시스템 프롬프트는 정적인 문자열일 수도 있고, 컨텍스트를 받아 문자열을 출력하는 동적 함수일 수도 있습니다. 이는 항상 유용한 정보(예: 사용자 이름 또는 현재 날짜)에 대한 일반적인 전술입니다\n+2. `Runner.run` 함수를 호출할 때 `input`에 추가합니다. 이는 `instructions` 전술과 유사하지만, [chain of command](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command)에서 더 낮은 수준의 메시지를 둘 수 있습니다\n+3. 함수 도구를 통해 노출합니다. 이는 _온디맨드_ 컨텍스트에 유용합니다. LLM이 언제 어떤 데이터가 필요한지 결정하고, 해당 데이터를 가져오기 위해 도구를 호출할 수 있습니다\n+4. retrieval 또는 웹 검색을 사용합니다. 이는 파일이나 데이터베이스에서 관련 데이터를 가져오거나(retrieval), 웹에서 가져올 수 있는(웹 검색) 특수 도구입니다. 이는 응답을 관련 컨텍스트 데이터에 \"그라운딩\"하는 데 유용합니다\n\\ No newline at end of file",
        "raw_url": "https://github.com/openai/openai-agents-python/raw/4d180fa0d132b29bc2a5a8f36302f08b576d1e77/docs%2Fko%2Fcontext.md",
        "sha": "784247f616e466113daac7f9d7f0c98ad7af2bba",
        "status": "modified"
      },
      {
        "additions": 30,
        "blob_url": "https://github.com/openai/openai-agents-python/blob/4d180fa0d132b29bc2a5a8f36302f08b576d1e77/docs%2Fzh%2Fcontext.md",
        "changes": 60,
        "contents_url": "https://api.github.com/repos/openai/openai-agents-python/contents/docs%2Fzh%2Fcontext.md?ref=4d180fa0d132b29bc2a5a8f36302f08b576d1e77",
        "deletions": 30,
        "filename": "docs/zh/context.md",
        "patch": "@@ -4,30 +4,30 @@ search:\n ---\n # 上下文管理\n \n-“上下文”一词含义广泛。通常你会关心两大类上下文：\n+上下文（Context）是一个含义很宽泛的术语。你可能会关注两类主要的上下文：\n \n-1. 代码本地可用的上下文：这是在工具函数运行、`on_handoff` 等回调、生命周期钩子中可能需要的数据和依赖。\n-2. LLM 可用的上下文：这是 LLM 在生成响应时可以看到的数据。\n+1. 你的代码在本地可用的上下文：这是在工具函数运行时、`on_handoff` 等回调期间、生命周期钩子中等场景可能需要的数据与依赖。\n+2. LLM 可用的上下文：这是 LLM 在生成响应时看到的数据。\n \n ## 本地上下文\n \n-这通过 [`RunContextWrapper`][agents.run_context.RunContextWrapper] 类以及其中的 [`context`][agents.run_context.RunContextWrapper.context] 属性来表示。其工作方式为：\n+这通过 [`RunContextWrapper`][agents.run_context.RunContextWrapper] 类以及其中的 [`context`][agents.run_context.RunContextWrapper.context] 属性来表示。其工作方式如下：\n \n-1. 你创建任意 Python 对象。常见做法是使用 dataclass 或 Pydantic 对象。\n-2. 将该对象传递给各类运行方法（例如 `Runner.run(..., **context=whatever**)`）。\n-3. 你的所有工具调用、生命周期钩子等都会接收到一个包装对象 `RunContextWrapper[T]`，其中 `T` 表示你的上下文对象类型，你可以通过 `wrapper.context` 访问。\n+1. 你创建任意你想要的 Python 对象。常见模式是使用 dataclass 或 Pydantic 对象。\n+2. 你将该对象传给各种 run 方法（例如 `Runner.run(..., context=whatever)`）。\n+3. 你所有的工具调用、生命周期钩子等都会收到一个包装对象 `RunContextWrapper[T]`，其中 `T` 表示你的上下文对象类型；你可以通过 `wrapper.context` 访问它。\n \n-需要特别注意的**最重要**事项：给定一次智能体运行，所有智能体、工具函数、生命周期等必须使用相同的上下文_类型_。\n+需要注意的**最重要**的一点是：对于一次给定的智能体运行，该运行中的每个智能体、工具函数、生命周期等都必须使用相同的上下文 _类型_。\n \n-你可以将上下文用于以下用途：\n+你可以用上下文来做这些事情，例如：\n \n-- 为运行提供上下文数据（例如用户名/uid 或关于用户的其他信息）\n-- 依赖（例如日志记录器对象、数据获取器等）\n-- 辅助函数\n+-   运行的上下文数据（例如用户名/uid 或其他与用户相关的信息）\n+-   依赖（例如 logger 对象、数据获取器等）\n+-   辅助函数\n \n !!! danger \"注意\"\n \n-    上下文对象**不会**发送给 LLM。它只是一个本地对象，你可以读取、写入并在其上调用方法。\n+    上下文对象**不会**发送给 LLM。它完全是一个本地对象，你可以从中读取、向其中写入并调用其方法。\n \n ```python\n import asyncio\n@@ -66,18 +66,18 @@ if __name__ == \"__main__\":\n     asyncio.run(main())\n ```\n \n-1. 这是上下文对象。此处使用了 dataclass，但你可以使用任意类型。\n-2. 这是一个工具。它接收 `RunContextWrapper[UserInfo]`。该工具的实现会从上下文中读取数据。\n-3. 我们用泛型 `UserInfo` 标注智能体，以便类型检查器能捕获错误（例如，如果我们尝试传入一个接收不同上下文类型的工具）。\n-4. 通过 `run` 函数传入上下文。\n-5. 智能体正确调用工具并获得年龄。\n+1. 这是上下文对象。这里我们使用了 dataclass，但你可以使用任何类型。\n+2. 这是一个工具。你可以看到它接收 `RunContextWrapper[UserInfo]`。该工具实现会从上下文中读取数据。\n+3. 我们用泛型 `UserInfo` 标注该智能体，这样类型检查器就能捕获错误（例如，如果我们尝试传入一个接收不同上下文类型的工具）。\n+4. 上下文被传入 `run` 函数。\n+5. 该智能体正确调用工具并获取年龄。\n \n ---\n \n-### 进阶：`ToolContext`\n+### 高级：`ToolContext`\n \n-在某些情况下，你可能需要访问正在执行的工具的额外元数据——例如其名称、调用 ID 或原始参数字符串。  \n-为此，你可以使用 [`ToolContext`][agents.tool_context.ToolContext] 类，它继承自 `RunContextWrapper`。\n+在某些情况下，你可能想访问正在执行的工具的额外元数据——例如工具名、调用 ID，或原始参数字符串。  \n+为此，你可以使用 [`ToolContext`][agents.tool_context.ToolContext] 类，它扩展了 `RunContextWrapper`。\n \n ```python\n from typing import Annotated\n@@ -106,22 +106,22 @@ agent = Agent(\n ```\n \n `ToolContext` 提供与 `RunContextWrapper` 相同的 `.context` 属性，  \n-并额外包含与当前工具调用相关的字段：\n+并额外提供当前工具调用特有的字段：\n \n - `tool_name` – 被调用工具的名称  \n - `tool_call_id` – 此次工具调用的唯一标识符  \n-- `tool_arguments` – 传递给工具的原始参数字符串  \n+- `tool_arguments` – 传给工具的原始参数字符串  \n \n-当你在执行期间需要工具级元数据时，请使用 `ToolContext`。  \n-对于智能体与工具之间的一般上下文共享，`RunContextWrapper` 已经足够。\n+当你在执行期间需要工具级元数据时，使用 `ToolContext`。  \n+对于智能体与工具之间的一般上下文共享，`RunContextWrapper` 仍然足够。\n \n ---\n \n ## 智能体/LLM 上下文\n \n-在调用 LLM 时，它能看到的**唯一**数据来自对话历史。这意味着若要让 LLM 获取新数据，必须以使其出现在对话历史中的方式提供。常见方法包括：\n+当调用 LLM 时，它能看到的**唯一**数据来自对话历史。这意味着，如果你想让一些新数据对 LLM 可用，你必须以一种能让它出现在历史中的方式来做。实现方式有几种：\n \n-1. 将其添加到智能体的 `instructions` 中。这也称为“系统提示词”或“开发者消息”。系统提示词可以是静态字符串，也可以是接收上下文并输出字符串的动态函数。对于始终有用的信息（例如用户名或当前日期），这是常见做法。\n-2. 在调用 `Runner.run` 时将其添加到 `input` 中。这与 `instructions` 的策略类似，但允许你在[指挥链](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command)中具有较低优先级的消息。\n-3. 通过 工具调用 暴露。这对于_按需_上下文很有用——LLM 会在需要某些数据时自行决定，并可调用工具获取该数据。\n-4. 使用 文件检索 或 网络检索。它们是能够从文件或数据库（文件检索），或从网络（网络检索）获取相关数据的特殊工具。这有助于使响应“落地”在相关的上下文数据上。\n\\ No newline at end of file\n+1. 你可以把它加入智能体的 `instructions`。这也被称为 “system prompt” 或 “developer message”。系统提示词可以是静态字符串，也可以是接收上下文并输出字符串的动态函数。这是针对始终有用的信息的常见策略（例如用户的名字或当前日期）。\n+2. 在调用 `Runner.run` 函数时，把它加入 `input`。这与 `instructions` 的策略类似，但允许你的消息在[指令优先级链](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command)中处于更低位置。\n+3. 通过工具调用暴露它。这适用于 _按需_ 上下文——LLM 决定何时需要某些数据，并可以调用工具来获取这些数据。\n+4. 使用检索或网络检索。这些是特殊工具，能够从文件或数据库（检索）或从网络（网络检索）中获取相关数据。这有助于将响应“落地”到相关的上下文数据之上。\n\\ No newline at end of file",
        "raw_url": "https://github.com/openai/openai-agents-python/raw/4d180fa0d132b29bc2a5a8f36302f08b576d1e77/docs%2Fzh%2Fcontext.md",
        "sha": "551464d188d1c4024758859b54f5e78f6f8010ba",
        "status": "modified"
      }
    ],
    "status": 200
  },
  "started_at": "2026-01-20T04:58:34.215816Z"
}
